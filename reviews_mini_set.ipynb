{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "#preprocessing\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from nltk.corpus import stopwords  #stopwords\n",
    "from nltk import word_tokenize,sent_tokenize # tokenizing\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer  # using the Porter Stemmer and Lancaster Stemmer and others\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
    "\n",
    "# for part-of-speech tagging\n",
    "from nltk import pos_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataCleaning_reviews_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151254\n",
      "{'reviewerID': 'A1VEELTKS8NLZB', 'asin': '616719923X', 'reviewerName': 'Amazon Customer', 'helpful': [0, 0], 'reviewText': 'Just another flavor of Kit Kat but the taste is unique and a bit different.  The only thing that is bothersome is the price.  I thought it was a bit expensive....', 'overall': 4.0, 'summary': 'Good Taste', 'unixReviewTime': 1370044800, 'reviewTime': '06 1, 2013'}\n",
      "151254\n"
     ]
    }
   ],
   "source": [
    "df5 = DataCleaning_reviews_5.data_clean('../reviews_Grocery_and_Gourmet_Food_5.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 151254 entries, 0 to 151253\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   reviewerID     151254 non-null  object \n",
      " 1   asin           151254 non-null  object \n",
      " 2   reviewerName   149761 non-null  object \n",
      " 3   reviewText     151254 non-null  object \n",
      " 4   helpful_votes  151254 non-null  object \n",
      " 5   rating         151254 non-null  float64\n",
      " 6   reviewTitle    151254 non-null  object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df5[['reviewText','reviewTitle', 'asin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTitle</th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just another flavor of Kit Kat but the taste i...</td>\n",
       "      <td>Good Taste</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I bought this on impulse and it comes from Jap...</td>\n",
       "      <td>3.5 stars,  sadly not as wonderful as I had hoped</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Really good. Great gift for any fan of green t...</td>\n",
       "      <td>Yum!</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I had never had it before, was curious to see ...</td>\n",
       "      <td>Unexpected flavor meld</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've been looking forward to trying these afte...</td>\n",
       "      <td>Not a very strong tea flavor, but still yummy ...</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  Just another flavor of Kit Kat but the taste i...   \n",
       "1  I bought this on impulse and it comes from Jap...   \n",
       "2  Really good. Great gift for any fan of green t...   \n",
       "3  I had never had it before, was curious to see ...   \n",
       "4  I've been looking forward to trying these afte...   \n",
       "\n",
       "                                         reviewTitle        asin  \n",
       "0                                         Good Taste  616719923X  \n",
       "1  3.5 stars,  sadly not as wonderful as I had hoped  616719923X  \n",
       "2                                               Yum!  616719923X  \n",
       "3                             Unexpected flavor meld  616719923X  \n",
       "4  Not a very strong tea flavor, but still yummy ...  616719923X  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(151254, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTitle</th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just another flavor of Kit Kat but the taste i...</td>\n",
       "      <td>Good Taste</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I bought this on impulse and it comes from Jap...</td>\n",
       "      <td>3.5 stars,  sadly not as wonderful as I had hoped</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Really good. Great gift for any fan of green t...</td>\n",
       "      <td>Yum!</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I had never had it before, was curious to see ...</td>\n",
       "      <td>Unexpected flavor meld</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've been looking forward to trying these afte...</td>\n",
       "      <td>Not a very strong tea flavor, but still yummy ...</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  Just another flavor of Kit Kat but the taste i...   \n",
       "1  I bought this on impulse and it comes from Jap...   \n",
       "2  Really good. Great gift for any fan of green t...   \n",
       "3  I had never had it before, was curious to see ...   \n",
       "4  I've been looking forward to trying these afte...   \n",
       "\n",
       "                                         reviewTitle        asin  \n",
       "0                                         Good Taste  616719923X  \n",
       "1  3.5 stars,  sadly not as wonderful as I had hoped  616719923X  \n",
       "2                                               Yum!  616719923X  \n",
       "3                             Unexpected flavor meld  616719923X  \n",
       "4  Not a very strong tea flavor, but still yummy ...  616719923X  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "print(df['reviewText'].isnull().sum())\n",
    "df['reviewTitle'].isnull().sum()  # no null values.\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-fab1430bca7a>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"all_text\"] = df[\"reviewText\"] + ' ' + df[\"reviewTitle\"]\n"
     ]
    }
   ],
   "source": [
    "df[\"all_text\"] = df[\"reviewText\"] + ' ' + df[\"reviewTitle\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTitle</th>\n",
       "      <th>asin</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just another flavor of Kit Kat but the taste i...</td>\n",
       "      <td>Good Taste</td>\n",
       "      <td>616719923X</td>\n",
       "      <td>Just another flavor of Kit Kat but the taste i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I bought this on impulse and it comes from Jap...</td>\n",
       "      <td>3.5 stars,  sadly not as wonderful as I had hoped</td>\n",
       "      <td>616719923X</td>\n",
       "      <td>I bought this on impulse and it comes from Jap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Really good. Great gift for any fan of green t...</td>\n",
       "      <td>Yum!</td>\n",
       "      <td>616719923X</td>\n",
       "      <td>Really good. Great gift for any fan of green t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I had never had it before, was curious to see ...</td>\n",
       "      <td>Unexpected flavor meld</td>\n",
       "      <td>616719923X</td>\n",
       "      <td>I had never had it before, was curious to see ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've been looking forward to trying these afte...</td>\n",
       "      <td>Not a very strong tea flavor, but still yummy ...</td>\n",
       "      <td>616719923X</td>\n",
       "      <td>I've been looking forward to trying these afte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  Just another flavor of Kit Kat but the taste i...   \n",
       "1  I bought this on impulse and it comes from Jap...   \n",
       "2  Really good. Great gift for any fan of green t...   \n",
       "3  I had never had it before, was curious to see ...   \n",
       "4  I've been looking forward to trying these afte...   \n",
       "\n",
       "                                         reviewTitle        asin  \\\n",
       "0                                         Good Taste  616719923X   \n",
       "1  3.5 stars,  sadly not as wonderful as I had hoped  616719923X   \n",
       "2                                               Yum!  616719923X   \n",
       "3                             Unexpected flavor meld  616719923X   \n",
       "4  Not a very strong tea flavor, but still yummy ...  616719923X   \n",
       "\n",
       "                                            all_text  \n",
       "0  Just another flavor of Kit Kat but the taste i...  \n",
       "1  I bought this on impulse and it comes from Jap...  \n",
       "2  Really good. Great gift for any fan of green t...  \n",
       "3  I had never had it before, was curious to see ...  \n",
       "4  I've been looking forward to trying these afte...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'make', 'claims', 'sports', 'nutrition', 'or', 'nutrition', 'matter', 'expertise', 'i', 'll', 'call', 'snack', 'leave', 'place', 'exercise', 'program', 'personal', 'doctor', 'nutritionist', 'coach', 'guru', 'however', 'i', 'say', 'much', 'better', 'average', 'tasting', 'sports', 'bar', 'snack', 'name', 'preference', 'free', 'cardboad', 'ish', 'stale', 'texture', 'barely', 'identifiable', 'aftertastes', 'common', 'similar', 'products', 'while', 'noone', 'compare', 'real', 'apple', 'crisp', 'convenient', 'food', 'go', 'recognizable', 'tastes', 'oats', 'this', 'flavor', 'texture', 'predominates', 'apple', 'cinnamon', 'due', 'large', 'part', 'i', 'suspect', 'fact', 'actually', 'contains', 'ingredients', 'there', 'also', 'raisins', 'cane', 'sugars', 'including', 'fructose', 'fruit', 'juices', 'giving', 'sweet', 'cloying', 'as', 'say', 'wineries', 'taste', 'this', 'company', 'known', 'quality', 'ingredients', 'generally', 'consumer', 'friendly', 'face', 'read', 'powerbar', 'com', 'the', 'company', 'recommends', 'consuming', 'water', 'aid', 'absorption', 'many', 'added', 'nutrients', 'this', 'also', 'gives', 'one', 'full', 'feeling', 'one', 'better', 'tasting', 'snacks', 'type', 'i', 've', 'listed', 'nutritional', 'information', 'ingredients', 'from', 'web', 'site', 'below', 'nutritional', 'information', 'percent', 'daily', 'values', 'dv', 'based', 'calorie', 'diet', 'in', 'one', 'serving', 'size', 'one', 'bar', 'total', 'grams', 'calories', 'calories', 'fat', 'dv', 'total', 'fat', 'g', 'dv', 'includes', 'grams', 'saturated', 'fat', 'and', 'g', 'as', 'none', 'trans', 'fat', 'no', 'cholesterol', 'mg', 'sodium', 'total', 'carbohydrates', 'fiber', 'sugars', 'does', 'anyone', 'carbo', 'load', 'anymore', 'protein', 'vitamins', 'minerals', 'vitamin', 'a', 'vitamin', 'c', 'calcium', 'iron', 'vitamin', 'e', 'thiamin', 'riboflavin', 'niacin', 'vitamin', 'folate', 'vitamin', 'biotin', 'pantothenic', 'acid', 'phosphorus', 'magnesium', 'zinc', 'copper', 'chromium', 'vitamin', 'k', 'iodine', 'manganese', 'molybdenum', 'selenium', 'ingredients', 'whole', 'oats', 'brown', 'rice', 'syrup', 'rice', 'crisps', 'milled', 'rice', 'sugar', 'salt', 'barley', 'malt', 'dried', 'apples', 'evaporated', 'cane', 'juice', 'syrup', 'raisins', 'roasted', 'soy', 'beans', 'almond', 'butter', 'honey', 'pear', 'grape', 'juice', 'concentrate', 'brown', 'rice', 'flour', 'soy', 'protein', 'isolate', 'glycerin', 'natural', 'flavors', 'cinnamon', 'nonfat', 'milk', 'possible', 'allergens', 'contains', 'milk', 'nut', 'soy', 'ingredients', 'made', 'equipment', 'also', 'processed', 'peanuts', 'wheat', 'salud', 'a', 'apple', 'crisp', 'a', 'day', 'does', 'something', 'you']\n"
     ]
    }
   ],
   "source": [
    "stemmer_porter=PorterStemmer()\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import string  \n",
    "snowball_stem = SnowballStemmer(language='english')\n",
    "s_words = set(stopwords.words('english'))\n",
    "punc = set(string.punctuation)\n",
    "def is_only_alpha(text):\n",
    "    return \" \".join([word for word in text.split() if word.isalpha()])\n",
    "def stemmers(llst):\n",
    "    return [stemmer_porter.stem(words) for words in llst]\n",
    "df['cleanText1']= df['all_text'].apply(lambda words:\" \".join([word for word in words.split() if word not in s_words]))\n",
    "df['cleanText2'] = df['cleanText1'].apply(lambda words:\" \".join([\"\".join([c if c not in punc else \" \" for c in word]) for word in words.split()]))\n",
    "df['cleanText3'] = df['cleanText2'].apply(is_only_alpha)\n",
    "df['cleanText4'] = df['cleanText3'].apply(word_tokenize)\n",
    "df['cleanText5'] = df['cleanText4'].apply(lambda words: [word.lower() for word in words])\n",
    "df['cleanText6'] = df['cleanText5'].apply(stemmers)\n",
    "df['cleanText7'] = df['cleanText6'].apply(lambda words: \" \".join(words))\n",
    "df = df.drop(['cleanText1','cleanText2','cleanText3','cleanText4','cleanText5','cleanText6'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=10_000, lowercase=False)\n",
    "X = vectorizer.fit_transform(df['cleanText7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[10:,10:].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    i want marinara sauc tast similar mom make fre...\n",
      "Name: cleanText7, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# X is the tf-idf of the reviews \n",
    "# y is the target or the inputed review from the user\n",
    "user_input = \"I want a marinara sauce that tastes similar to how my mom makes it with fresh tomatoes, garlic, basil, and olive oil.\"\n",
    "user_df = pd.DataFrame({'user1': [user_input]})\n",
    "def is_only_alpha(text):\n",
    "    return \" \".join([word for word in text.split() if word.isalpha()])\n",
    "def stemmers(llst):\n",
    "    return [stemmer_porter.stem(words) for words in llst]\n",
    "user_df['cleanText1']= user_df['user1'].apply(lambda words:\" \".join([word for word in words.split() if word not in s_words]))\n",
    "user_df['cleanText2'] = user_df['cleanText1'].apply(lambda words:\" \".join([\"\".join([c if c not in punc else \" \" for c in word]) for word in words.split()]))\n",
    "user_df['cleanText3'] = user_df['cleanText2'].apply(is_only_alpha)\n",
    "user_df['cleanText4'] = user_df['cleanText3'].apply(word_tokenize)\n",
    "user_df['cleanText5'] = user_df['cleanText4'].apply(lambda words: [word.lower() for word in words])\n",
    "user_df['cleanText6'] = user_df['cleanText5'].apply(stemmers)\n",
    "user_df['cleanText7'] = user_df['cleanText6'].apply(lambda words: \" \".join(words))\n",
    "#print(user_df['cleanText7'])\n",
    "#user_df = df.drop(['cleanText1','cleanText2','cleanText3','cleanText4','cleanText5','cleanText6'],axis=1)\n",
    "y = vectorizer.transform([user_df['cleanText7'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75626, 87463, 36845, ..., 38110,  2959, 15071]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sim_matrix = cosine_similarity(y,X)\n",
    "sim_sorted= np.argsort(sim_matrix)[::-1] # idx of lowest value to highest value but with ::-1 its decending\n",
    "sim_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'these realli great tomato i hate metal tast can tomato tast like chanc leach tomato can t healthi these rich flavor wateri great sauc virgin oliv oil fresh basil garlic s p cook pasta firm finish cook sauc simpl delici love tomato wish i could find local least i get amazon ever without amazon no tinni metal tast'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleanText7'][sim_sorted[0][-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[103184,  62671,  33582, ...,  74295, 117112,  70191]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i love to cook so i bought it for when price get to high for me to buy it ani more love it'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.amazon.com/dp/B002TMV3E4',\n",
       " 'http://www.amazon.com/dp/B000EZ7J9G',\n",
       " 'http://www.amazon.com/dp/B0005ZVOR8',\n",
       " 'http://www.amazon.com/dp/B0012HP1CC',\n",
       " 'http://www.amazon.com/dp/B000LKZ9IC',\n",
       " 'http://www.amazon.com/dp/B000EZ7J9G',\n",
       " 'http://www.amazon.com/dp/B000LKXG64',\n",
       " 'http://www.amazon.com/dp/B001SAYKJS',\n",
       " 'http://www.amazon.com/dp/B000F3Q4AM',\n",
       " 'http://www.amazon.com/dp/B000MMO8W2']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_asin_top1 = df.iloc[sim_sorted[0][-8]].loc['asin']\n",
    "item_asin_top1\n",
    "item_asin_top10 = []\n",
    "for i in range(10):\n",
    "    item_asin_top10.append(df.iloc[sim_sorted[0][-i]].loc['asin'])\n",
    "top10_url = []\n",
    "for asin in item_asin_top10:\n",
    "    url = \"http://www.amazon.com/dp/\"+asin\n",
    "    top10_url.append(url)\n",
    "top10_url\n",
    "\n",
    "# now I have to find if one of these is glutine free, \n",
    "#organic or keto and stuff like that. also try to find if I can \n",
    "# find broken links by cleaining up the reviews with only ones in meta\n",
    "# berfore that I have to use meta to find the ones that have organic or glutine free\n",
    "# then clean up reviews using only the ones that i have in meta after the fact\n",
    "# and then clean up the recomendations so it doesnt rocomend only the same item like \n",
    "# pop tars and tomato sause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataCleaning_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287051\n",
      "{'category': ['Grocery & Gourmet Food', 'Dairy, Cheese & Eggs', 'Cheese', 'Gouda'], 'tech1': '', 'description': ['BEEMSTER GOUDA CHEESE AGED 18/24 MONTHS', 'Statements regarding dietary supplements have not been evaluated by the FDA and are not intended to diagnose, treat, cure, or prevent any disease or health condition.'], 'fit': '', 'title': 'Beemster Gouda - Aged 18/24 Months - App. 1.5 Lbs', 'also_buy': [], 'image': [], 'tech2': '', 'brand': 'Ariola Imports', 'feature': [], 'rank': '165,181 in Grocery & Gourmet Food (', 'also_view': ['B0000D9MYM', 'B0000D9MYL', 'B00ADHIGBA', 'B00H9OX598', 'B001LM42GY', 'B001LM5TDY'], 'main_cat': 'Grocery', 'similar_item': '', 'date': '', 'price': '$41.91', 'asin': '0681727810'}\n",
      "287051\n"
     ]
    }
   ],
   "source": [
    "df_meta = DataCleaning_meta.data_clean_meta(\"../meta_Grocery_and_Gourmet_Food.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>brand</th>\n",
       "      <th>rank</th>\n",
       "      <th>price</th>\n",
       "      <th>asin</th>\n",
       "      <th>name</th>\n",
       "      <th>features</th>\n",
       "      <th>categories</th>\n",
       "      <th>main_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12553</th>\n",
       "      <td>[Fresh. Fast. Easy. Gluten free. Vegetarian. W...</td>\n",
       "      <td>Scarpetta</td>\n",
       "      <td>[]</td>\n",
       "      <td>$28.40</td>\n",
       "      <td>B000F3Q4AM</td>\n",
       "      <td>Scarpetta Marinara Sauce, 19.8-Ounce Jars (Pac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Grocery &amp; Gourmet Food, Sauces, Gravies &amp; Mar...</td>\n",
       "      <td>Grocery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description      brand rank  \\\n",
       "12553  [Fresh. Fast. Easy. Gluten free. Vegetarian. W...  Scarpetta   []   \n",
       "\n",
       "        price        asin                                               name  \\\n",
       "12553  $28.40  B000F3Q4AM  Scarpetta Marinara Sauce, 19.8-Ounce Jars (Pac...   \n",
       "\n",
       "      features                                         categories  \\\n",
       "12553       []  [Grocery & Gourmet Food, Sauces, Gravies & Mar...   \n",
       "\n",
       "      main_category  \n",
       "12553       Grocery  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta[df_meta['asin'] == item_asin_top1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTitle</th>\n",
       "      <th>asin</th>\n",
       "      <th>all_text</th>\n",
       "      <th>cleanText6</th>\n",
       "      <th>cleanText7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just another flavor of Kit Kat but the taste i...</td>\n",
       "      <td>Good Taste</td>\n",
       "      <td>616719923X</td>\n",
       "      <td>Just another flavor of Kit Kat but the taste i...</td>\n",
       "      <td>[just, anoth, flavor, kit, kat, tast, uniqu, b...</td>\n",
       "      <td>just anoth flavor kit kat tast uniqu bit diffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I bought this on impulse and it comes from Jap...</td>\n",
       "      <td>3.5 stars,  sadly not as wonderful as I had hoped</td>\n",
       "      <td>616719923X</td>\n",
       "      <td>I bought this on impulse and it comes from Jap...</td>\n",
       "      <td>[i, bought, impuls, come, japan, amus, famili,...</td>\n",
       "      <td>i bought impuls come japan amus famili weird s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Really good. Great gift for any fan of green t...</td>\n",
       "      <td>Yum!</td>\n",
       "      <td>616719923X</td>\n",
       "      <td>Really good. Great gift for any fan of green t...</td>\n",
       "      <td>[realli, good, great, gift, fan, green, tea, j...</td>\n",
       "      <td>realli good great gift fan green tea just expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I had never had it before, was curious to see ...</td>\n",
       "      <td>Unexpected flavor meld</td>\n",
       "      <td>616719923X</td>\n",
       "      <td>I had never had it before, was curious to see ...</td>\n",
       "      <td>[i, never, befor, curiou, see, like, smooth, g...</td>\n",
       "      <td>i never befor curiou see like smooth great sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've been looking forward to trying these afte...</td>\n",
       "      <td>Not a very strong tea flavor, but still yummy ...</td>\n",
       "      <td>616719923X</td>\n",
       "      <td>I've been looking forward to trying these afte...</td>\n",
       "      <td>[i, ve, look, forward, tri, hear, popular, jap...</td>\n",
       "      <td>i ve look forward tri hear popular japan among...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  Just another flavor of Kit Kat but the taste i...   \n",
       "1  I bought this on impulse and it comes from Jap...   \n",
       "2  Really good. Great gift for any fan of green t...   \n",
       "3  I had never had it before, was curious to see ...   \n",
       "4  I've been looking forward to trying these afte...   \n",
       "\n",
       "                                         reviewTitle        asin  \\\n",
       "0                                         Good Taste  616719923X   \n",
       "1  3.5 stars,  sadly not as wonderful as I had hoped  616719923X   \n",
       "2                                               Yum!  616719923X   \n",
       "3                             Unexpected flavor meld  616719923X   \n",
       "4  Not a very strong tea flavor, but still yummy ...  616719923X   \n",
       "\n",
       "                                            all_text  \\\n",
       "0  Just another flavor of Kit Kat but the taste i...   \n",
       "1  I bought this on impulse and it comes from Jap...   \n",
       "2  Really good. Great gift for any fan of green t...   \n",
       "3  I had never had it before, was curious to see ...   \n",
       "4  I've been looking forward to trying these afte...   \n",
       "\n",
       "                                          cleanText6  \\\n",
       "0  [just, anoth, flavor, kit, kat, tast, uniqu, b...   \n",
       "1  [i, bought, impuls, come, japan, amus, famili,...   \n",
       "2  [realli, good, great, gift, fan, green, tea, j...   \n",
       "3  [i, never, befor, curiou, see, like, smooth, g...   \n",
       "4  [i, ve, look, forward, tri, hear, popular, jap...   \n",
       "\n",
       "                                          cleanText7  \n",
       "0  just anoth flavor kit kat tast uniqu bit diffe...  \n",
       "1  i bought impuls come japan amus famili weird s...  \n",
       "2  realli good great gift fan green tea just expe...  \n",
       "3  i never befor curiou see like smooth great sub...  \n",
       "4  i ve look forward tri hear popular japan among...  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 151254 entries, 0 to 151253\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   reviewText   151254 non-null  object\n",
      " 1   reviewTitle  151254 non-null  object\n",
      " 2   asin         151254 non-null  object\n",
      " 3   all_text     151254 non-null  object\n",
      " 4   cleanText6   151254 non-null  object\n",
      " 5   cleanText7   151254 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 13.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BEEMSTER GOUDA CHEESE AGED 18/24 MONTHS',\n",
       " 'Statements regarding dietary supplements have not been evaluated by the FDA and are not intended to diagnose, treat, cure, or prevent any disease or health condition.']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta['description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_life = df_meta[df_meta['main_category'] == 'Grocery']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-198-419902078dea>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta_life['all_text'] = df_meta_life['description'].astype(str) + ' ' + df_meta_life['name'].astype(str) + \" \" + df_meta_life['categories'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "df_meta_life['all_text'] = df_meta_life['description'].astype(str) + ' ' + df_meta_life['name'].astype(str) + \" \" + df_meta_life['categories'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nico/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df_meta_life.drop(['clean_all_text'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-205-f2e0972a3538>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta_life['cleanText1'] = df_meta_life['description'].apply(lambda words: \" \".join(words)).apply(lambda words:\" \".join([word for word in words.split() if word not in s_words]))\n",
      "<ipython-input-205-f2e0972a3538>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta_life['cleanText2'] = df_meta_life['cleanText1'].apply(lambda words:\" \".join([\"\".join([c if c not in punc else \" \" for c in word]) for word in words.split()]))\n",
      "<ipython-input-205-f2e0972a3538>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta_life['cleanText3'] = df_meta_life['cleanText2'].apply(is_only_alpha)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-f2e0972a3538>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf_meta_life\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleanText2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_meta_life\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleanText1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpunc\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_meta_life\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleanText3'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_meta_life\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleanText2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_only_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_meta_life\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleanText4'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_meta_life\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleanText3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdf_meta_life\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleanText5'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_meta_life\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleanText4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdf_meta_life\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleanText5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m    129\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     return [\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     ]\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     return [\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     ]\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/tokenize/destructive.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONTRACTIONS2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\" \\1 \\2 \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONTRACTIONS3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\" \\1 \\2 \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def is_only_alpha(text):\n",
    "    return \" \".join([word for word in text.split() if word.isalpha()])\n",
    "def stemmers(llst):\n",
    "    return [stemmer_porter.stem(words) for words in llst]\n",
    "df_meta_life['cleanText1'] = df_meta_life['description'].apply(lambda words: \" \".join(words)).apply(lambda words:\" \".join([word for word in words.split() if word not in s_words]))\n",
    "df_meta_life['cleanText2'] = df_meta_life['cleanText1'].apply(lambda words:\" \".join([\"\".join([c if c not in punc else \" \" for c in word]) for word in words.split()]))\n",
    "df_meta_life['cleanText3'] = df_meta_life['cleanText2'].apply(is_only_alpha)\n",
    "df_meta_life['cleanText4'] = df_meta_life['cleanText3'].apply(word_tokenize)\n",
    "df_meta_life['cleanText5'] = df_meta_life['cleanText4'].apply(lambda words: [word.lower() for word in words])\n",
    "df_meta_life['cleanText5'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beemster',\n",
       " 'gouda',\n",
       " 'cheese',\n",
       " 'aged',\n",
       " 'months',\n",
       " 'statements',\n",
       " 'regarding',\n",
       " 'dietary',\n",
       " 'supplements',\n",
       " 'evaluated',\n",
       " 'fda',\n",
       " 'intended',\n",
       " 'diagnose',\n",
       " 'treat',\n",
       " 'cure',\n",
       " 'prevent',\n",
       " 'disease',\n",
       " 'health',\n",
       " 'condition']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_life['cleanText5'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lifestyle(df):\n",
    "    lifestyles = ['vegetarian','paleo Diet','keto', 'vegan','lowsugar','gluten free','low fat',\"organic\", \"nongmo\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
