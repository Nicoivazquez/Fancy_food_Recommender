{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "#preprocessing\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from nltk.corpus import stopwords  #stopwords\n",
    "from nltk import word_tokenize,sent_tokenize # tokenizing\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer  # using the Porter Stemmer and Lancaster Stemmer and others\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
    "\n",
    "# for part-of-speech tagging\n",
    "from nltk import pos_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataCleaning_reviews_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302508\n",
      "{'reviewerID': 'A1VEELTKS8NLZB', 'asin': '616719923X', 'reviewerName': 'Amazon Customer', 'helpful': [0, 0], 'reviewText': 'Just another flavor of Kit Kat but the taste is unique and a bit different.  The only thing that is bothersome is the price.  I thought it was a bit expensive....', 'overall': 4.0, 'summary': 'Good Taste', 'unixReviewTime': 1370044800, 'reviewTime': '06 1, 2013'}\n",
      "302508\n"
     ]
    }
   ],
   "source": [
    "df5 = DataCleaning_reviews_5.data_clean('../reviews_Grocery_and_Gourmet_Food_5.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 151254 entries, 0 to 151253\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   reviewerID     151254 non-null  object \n",
      " 1   asin           151254 non-null  object \n",
      " 2   reviewerName   149761 non-null  object \n",
      " 3   reviewText     151254 non-null  object \n",
      " 4   helpful_votes  151254 non-null  object \n",
      " 5   rating         151254 non-null  float64\n",
      " 6   reviewTitle    151254 non-null  object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df5[['reviewText','reviewTitle', 'asin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTitle</th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just another flavor of Kit Kat but the taste i...</td>\n",
       "      <td>Good Taste</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I bought this on impulse and it comes from Jap...</td>\n",
       "      <td>3.5 stars,  sadly not as wonderful as I had hoped</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Really good. Great gift for any fan of green t...</td>\n",
       "      <td>Yum!</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I had never had it before, was curious to see ...</td>\n",
       "      <td>Unexpected flavor meld</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've been looking forward to trying these afte...</td>\n",
       "      <td>Not a very strong tea flavor, but still yummy ...</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  Just another flavor of Kit Kat but the taste i...   \n",
       "1  I bought this on impulse and it comes from Jap...   \n",
       "2  Really good. Great gift for any fan of green t...   \n",
       "3  I had never had it before, was curious to see ...   \n",
       "4  I've been looking forward to trying these afte...   \n",
       "\n",
       "                                         reviewTitle        asin  \n",
       "0                                         Good Taste  616719923X  \n",
       "1  3.5 stars,  sadly not as wonderful as I had hoped  616719923X  \n",
       "2                                               Yum!  616719923X  \n",
       "3                             Unexpected flavor meld  616719923X  \n",
       "4  Not a very strong tea flavor, but still yummy ...  616719923X  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(151254, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTitle</th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just another flavor of Kit Kat but the taste i...</td>\n",
       "      <td>Good Taste</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I bought this on impulse and it comes from Jap...</td>\n",
       "      <td>3.5 stars,  sadly not as wonderful as I had hoped</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Really good. Great gift for any fan of green t...</td>\n",
       "      <td>Yum!</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I had never had it before, was curious to see ...</td>\n",
       "      <td>Unexpected flavor meld</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've been looking forward to trying these afte...</td>\n",
       "      <td>Not a very strong tea flavor, but still yummy ...</td>\n",
       "      <td>616719923X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  Just another flavor of Kit Kat but the taste i...   \n",
       "1  I bought this on impulse and it comes from Jap...   \n",
       "2  Really good. Great gift for any fan of green t...   \n",
       "3  I had never had it before, was curious to see ...   \n",
       "4  I've been looking forward to trying these afte...   \n",
       "\n",
       "                                         reviewTitle        asin  \n",
       "0                                         Good Taste  616719923X  \n",
       "1  3.5 stars,  sadly not as wonderful as I had hoped  616719923X  \n",
       "2                                               Yum!  616719923X  \n",
       "3                             Unexpected flavor meld  616719923X  \n",
       "4  Not a very strong tea flavor, but still yummy ...  616719923X  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "print(df['reviewText'].isnull().sum())\n",
    "df['reviewTitle'].isnull().sum()  # no null values.\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-133-fab1430bca7a>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"all_text\"] = df[\"reviewText\"] + ' ' + df[\"reviewTitle\"]\n"
     ]
    }
   ],
   "source": [
    "df[\"all_text\"] = df[\"reviewText\"] + ' ' + df[\"reviewTitle\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c42a15b2c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-135-9b8d129e3e2b>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cleanText1']= df['all_text'].apply(lambda words:\" \".join([word for word in words.split() if word not in s_words]))\n",
      "<ipython-input-135-9b8d129e3e2b>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cleanText2'] = df['cleanText1'].apply(lambda words:\" \".join([\"\".join([c if c not in punc else \" \" for c in word]) for word in words.split()]))\n"
     ]
    }
   ],
   "source": [
    "stemmer_porter=PorterStemmer()\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import string  \n",
    "snowball_stem = SnowballStemmer(language='english')\n",
    "s_words = set(stopwords.words('english'))\n",
    "punc = set(string.punctuation)\n",
    "def is_only_alpha(text):\n",
    "    return \" \".join([word for word in text.split() if word.isalpha()])\n",
    "def stemmers(llst):\n",
    "    return [stemmer_porter.stem(words) for words in llst]\n",
    "df['cleanText1']= df['all_text'].apply(lambda words:\" \".join([word for word in words.split() if word not in s_words]))\n",
    "df['cleanText2'] = df['cleanText1'].apply(lambda words:\" \".join([\"\".join([c if c not in punc else \" \" for c in word]) for word in words.split()]))\n",
    "df['cleanText3'] = df['cleanText2'].apply(is_only_alpha)\n",
    "df['cleanText4'] = df['cleanText3'].apply(word_tokenize)\n",
    "df['cleanText5'] = df['cleanText4'].apply(lambda words: [word.lower() for word in words])\n",
    "df['cleanText6'] = df['cleanText5'].apply(stemmers)\n",
    "df['cleanText7'] = df['cleanText6'].apply(lambda words: \" \".join(words))\n",
    "df = df.drop(['cleanText1','cleanText2','cleanText3','cleanText4','cleanText5','cleanText6'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=10_000, lowercase=False)\n",
    "X = vectorizer.fit_transform(df['cleanText7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.20658839, 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[10:,10:].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is the tf-idf of the reviews \n",
    "# y is the target or the inputed review from the user\n",
    "user_input = \"Without a doubt, pizza is the greatest food that has ever been developed. It has all the major food groups, an nice mix of carbohydrates, protein, calcium, and can be loaded down the vegetables. Some people don't like the gluten in the crust, so a gluten-free option is like hitting the trifecta.\"\n",
    "user_df = pd.DataFrame({'user1': [user_input]})\n",
    "def is_only_alpha(text):\n",
    "    return \" \".join([word for word in text.split() if word.isalpha()])\n",
    "def stemmers(llst):\n",
    "    return [stemmer_porter.stem(words) for words in llst]\n",
    "user_df['cleanText1']= user_df['user1'].apply(lambda words:\" \".join([word for word in words.split() if word not in s_words]))\n",
    "user_df['cleanText2'] = user_df['cleanText1'].apply(lambda words:\" \".join([\"\".join([c if c not in punc else \" \" for c in word]) for word in words.split()]))\n",
    "user_df['cleanText3'] = user_df['cleanText2'].apply(is_only_alpha)\n",
    "user_df['cleanText4'] = user_df['cleanText3'].apply(word_tokenize)\n",
    "user_df['cleanText5'] = user_df['cleanText4'].apply(lambda words: [word.lower() for word in words])\n",
    "user_df['cleanText6'] = user_df['cleanText5'].apply(stemmers)\n",
    "user_df['cleanText7'] = user_df['cleanText6'].apply(lambda words: \" \".join(words))\n",
    "#print(user_df['cleanText7'])\n",
    "user_df = df.drop(['cleanText1','cleanText2','cleanText3','cleanText4','cleanText5','cleanText6'],axis=1)\n",
    "y = vectorizer.transform([user_df['cleanText7'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75626, 87463, 36845, ..., 38110,  2959, 15071]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sim_matrix = cosine_similarity(y,X)\n",
    "sim_sorted= np.argsort(sim_matrix)[::-1] # idx of lowest value to highest value but with ::-1 its decending\n",
    "sim_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'these realli great tomato i hate metal tast can tomato tast like chanc leach tomato can t healthi these rich flavor wateri great sauc virgin oliv oil fresh basil garlic s p cook pasta firm finish cook sauc simpl delici love tomato wish i could find local least i get amazon ever without amazon no tinni metal tast'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleanText7'][sim_sorted[0][-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0f8058993cae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mitem_asin_top1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msim_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'asin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mitem_asin_top1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mitem_asin_top10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mitem_asin_top10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msim_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'asin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "item_asin_top1 = df.iloc[sim_sorted[0][-8]].loc['asin']\n",
    "item_asin_top1\n",
    "item_asin_top10 = []\n",
    "for i in range(10):\n",
    "    item_asin_top10.append(df.iloc[sim_sorted[0][-i]].loc['asin'])\n",
    "top10_url = []\n",
    "for asin in item_asin_top10:\n",
    "    url = \"http://www.amazon.com/dp/\"+asin\n",
    "    top10_url.append(url)\n",
    "top10_url\n",
    "\n",
    "# now I have to find if one of these is glutine free, \n",
    "#organic or keto and stuff like that. also try to find if I can \n",
    "# find broken links by cleaining up the reviews with only ones in meta\n",
    "# berfore that I have to use meta to find the ones that have organic or glutine free\n",
    "# then clean up reviews using only the ones that i have in meta after the fact\n",
    "# and then clean up the recomendations so it doesnt rocomend only the same item like \n",
    "# pop tars and tomato sause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataCleaning_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = DataCleaning_meta.data_clean_meta(\"../fmeta_Grocery_and_Gourmet_Food.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta[df_meta['asin'] == item_asin_top1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTitle</th>\n",
       "      <th>asin</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just another flavor of Kit Kat but the taste i...</td>\n",
       "      <td>Good Taste</td>\n",
       "      <td>616719923X</td>\n",
       "      <td>Just another flavor of Kit Kat but the taste i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I bought this on impulse and it comes from Jap...</td>\n",
       "      <td>3.5 stars,  sadly not as wonderful as I had hoped</td>\n",
       "      <td>616719923X</td>\n",
       "      <td>I bought this on impulse and it comes from Jap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Really good. Great gift for any fan of green t...</td>\n",
       "      <td>Yum!</td>\n",
       "      <td>616719923X</td>\n",
       "      <td>Really good. Great gift for any fan of green t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I had never had it before, was curious to see ...</td>\n",
       "      <td>Unexpected flavor meld</td>\n",
       "      <td>616719923X</td>\n",
       "      <td>I had never had it before, was curious to see ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've been looking forward to trying these afte...</td>\n",
       "      <td>Not a very strong tea flavor, but still yummy ...</td>\n",
       "      <td>616719923X</td>\n",
       "      <td>I've been looking forward to trying these afte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  Just another flavor of Kit Kat but the taste i...   \n",
       "1  I bought this on impulse and it comes from Jap...   \n",
       "2  Really good. Great gift for any fan of green t...   \n",
       "3  I had never had it before, was curious to see ...   \n",
       "4  I've been looking forward to trying these afte...   \n",
       "\n",
       "                                         reviewTitle        asin  \\\n",
       "0                                         Good Taste  616719923X   \n",
       "1  3.5 stars,  sadly not as wonderful as I had hoped  616719923X   \n",
       "2                                               Yum!  616719923X   \n",
       "3                             Unexpected flavor meld  616719923X   \n",
       "4  Not a very strong tea flavor, but still yummy ...  616719923X   \n",
       "\n",
       "                                            all_text  \n",
       "0  Just another flavor of Kit Kat but the taste i...  \n",
       "1  I bought this on impulse and it comes from Jap...  \n",
       "2  Really good. Great gift for any fan of green t...  \n",
       "3  I had never had it before, was curious to see ...  \n",
       "4  I've been looking forward to trying these afte...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 151254 entries, 0 to 151253\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   reviewText   151254 non-null  object\n",
      " 1   reviewTitle  151254 non-null  object\n",
      " 2   asin         151254 non-null  object\n",
      " 3   all_text     151254 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dishes cooked with nutrela are very tasty and also have natural nutritive goodness. Statements regarding dietary supplements have not been evaluated by the FDA and are not intended to diagnose, treat, cure, or prevent any disease or health condition. Nutrela High Protein Soya Chunks 200g (Pack of 6) Grocery & Gourmet Food Canned, Jarred & Packaged Foods Packaged Meals & Side Dishes Indian Dishes'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-7fd8966e5400>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta_life['all_text'] = df_meta_life['description'] + ' ' + df_meta_life['name']\n",
      "<ipython-input-26-7fd8966e5400>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta_life['all_text'] = df_meta_life['all_text'] + ' ' + df_meta_life['categories']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-93982334f33a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_meta_life\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'all_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4403\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4404\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4405\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4406\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 4"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-52-14342b4481e2>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta_life['cleanText1']= df_meta_life['all_text'].apply(lambda words:\" \".join([word for word in words.split() if word not in s_words]))\n",
      "<ipython-input-52-14342b4481e2>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta_life['cleanText2'] = df_meta_life['cleanText1'].apply(lambda words:\" \".join([\"\".join([c if c not in punc else \" \" for c in word]) for word in words.split()]))\n",
      "<ipython-input-52-14342b4481e2>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta_life['cleanText3'] = df_meta_life['cleanText2'].apply(is_only_alpha)\n",
      "<ipython-input-52-14342b4481e2>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta_life['cleanText4'] = df_meta_life['cleanText3'].apply(word_tokenize)\n",
      "<ipython-input-52-14342b4481e2>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta_life['cleanText5'] = df_meta_life['cleanText4'].apply(lambda words: [word.lower() for word in words])\n",
      "<ipython-input-52-14342b4481e2>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta_life['cleanText6'] = df_meta_life['cleanText5'].apply(stemmers)\n",
      "<ipython-input-52-14342b4481e2>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta_life['cleanText7'] = df_meta_life['cleanText6'].apply(lambda words: \" \".join(words))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'beemster gouda chees age month statement regard dietari supplement evalu fda intend diagnos treat cure prevent diseas health condit beemster gouda age month app lb groceri gourmet food dairi chees egg chees gouda'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_life['cleanText7'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_only_alpha(text):\n",
    "#     return \" \".join([word for word in text.split() if word.isalpha()])\n",
    "# def stemmers(llst):\n",
    "#     return [stemmer_porter.stem(words) for words in llst]\n",
    "# df_meta_life['cleanText1']= df_meta_life['all_text'].apply(lambda words:\" \".join([word for word in words.split() if word not in s_words]))\n",
    "# df_meta_life['cleanText2'] = df_meta_life['cleanText1'].apply(lambda words:\" \".join([\"\".join([c if c not in punc else \" \" for c in word]) for word in words.split()]))\n",
    "# df_meta_life['cleanText3'] = df_meta_life['cleanText2'].apply(is_only_alpha)\n",
    "# df_meta_life['cleanText4'] = df_meta_life['cleanText3'].apply(word_tokenize)\n",
    "# df_meta_life['cleanText5'] = df_meta_life['cleanText4'].apply(lambda words: [word.lower() for word in words])\n",
    "\n",
    "# df_meta_life['cleanText6'] = df_meta_life['cleanText5'].apply(lambda words: \" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 261845 entries, 0 to 287050\n",
      "Data columns (total 17 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   description    261845 non-null  object\n",
      " 1   brand          261845 non-null  object\n",
      " 2   rank           261845 non-null  object\n",
      " 3   price          261845 non-null  object\n",
      " 4   asin           261845 non-null  object\n",
      " 5   name           261845 non-null  object\n",
      " 6   features       261845 non-null  object\n",
      " 7   categories     261845 non-null  object\n",
      " 8   main_category  261845 non-null  object\n",
      " 9   all_text       261845 non-null  object\n",
      " 10  cleanText1     261845 non-null  object\n",
      " 11  cleanText2     261845 non-null  object\n",
      " 12  cleanText3     261845 non-null  object\n",
      " 13  cleanText4     261845 non-null  object\n",
      " 14  cleanText5     261845 non-null  object\n",
      " 15  cleanText6     261845 non-null  object\n",
      " 16  cleanText7     261845 non-null  object\n",
      "dtypes: object(17)\n",
      "memory usage: 46.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_meta_life.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifestyles = ['vegetarian?','paleo?','keto?', 'vegan?','lowsugar?',\"low sugar\",'gluten free', \"gluten\",'low gluten',\"pescaterian\",'low fat','fat free','free fat',\"organic?\", \"gmo\",'sugar?' ,'subsitutes','indian', \"Kosher\", \"halal\", 'Ovo lacto','lacto?']\n",
    "df_meta_filtered = df_meta_life[df_meta_life['cleanText7'].str.contains('|'.join(lifestyles))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>brand</th>\n",
       "      <th>rank</th>\n",
       "      <th>price</th>\n",
       "      <th>asin</th>\n",
       "      <th>name</th>\n",
       "      <th>features</th>\n",
       "      <th>categories</th>\n",
       "      <th>main_category</th>\n",
       "      <th>all_text</th>\n",
       "      <th>cleanText1</th>\n",
       "      <th>cleanText2</th>\n",
       "      <th>cleanText3</th>\n",
       "      <th>cleanText4</th>\n",
       "      <th>cleanText5</th>\n",
       "      <th>cleanText6</th>\n",
       "      <th>cleanText7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shipped from UK, please allow 10 to 21 busines...</td>\n",
       "      <td></td>\n",
       "      <td>315,867 in Grocery &amp; Gourmet Food (</td>\n",
       "      <td></td>\n",
       "      <td>0853347867</td>\n",
       "      <td>Trim Healthy Mama Xylitol</td>\n",
       "      <td>[]</td>\n",
       "      <td>Grocery &amp; Gourmet Food Cooking &amp; Baking Sugar ...</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>Shipped from UK, please allow 10 to 21 busines...</td>\n",
       "      <td>Shipped UK, please allow 10 21 business days a...</td>\n",
       "      <td>Shipped UK  please allow 10 21 business days a...</td>\n",
       "      <td>Shipped UK please allow business days arrival ...</td>\n",
       "      <td>[Shipped, UK, please, allow, business, days, a...</td>\n",
       "      <td>[shipped, uk, please, allow, business, days, a...</td>\n",
       "      <td>[ship, uk, pleas, allow, busi, day, arriv, ex,...</td>\n",
       "      <td>ship uk pleas allow busi day arriv ex lib pub ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dishes cooked with nutrela are very tasty and ...</td>\n",
       "      <td>Nutrela</td>\n",
       "      <td>195,125 in Grocery &amp; Gourmet Food (</td>\n",
       "      <td>$24.99</td>\n",
       "      <td>5236363640</td>\n",
       "      <td>Nutrela High Protein Soya Chunks 200g (Pack of 6)</td>\n",
       "      <td>[]</td>\n",
       "      <td>Grocery &amp; Gourmet Food Canned, Jarred &amp; Packag...</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>Dishes cooked with nutrela are very tasty and ...</td>\n",
       "      <td>Dishes cooked nutrela tasty also natural nutri...</td>\n",
       "      <td>Dishes cooked nutrela tasty also natural nutri...</td>\n",
       "      <td>Dishes cooked nutrela tasty also natural nutri...</td>\n",
       "      <td>[Dishes, cooked, nutrela, tasty, also, natural...</td>\n",
       "      <td>[dishes, cooked, nutrela, tasty, also, natural...</td>\n",
       "      <td>[dish, cook, nutrela, tasti, also, natur, nutr...</td>\n",
       "      <td>dish cook nutrela tasti also natur nutrit good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Haldiram&amp;apos;s Bhelpuri - A Mild Spicy Blend ...</td>\n",
       "      <td>Haldirams</td>\n",
       "      <td>72,407 in Grocery &amp; Gourmet Food (</td>\n",
       "      <td>$18.99</td>\n",
       "      <td>541255556X</td>\n",
       "      <td>Haldiram's Bhelpuri - A Mild Spicy Blend of Cr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Grocery &amp; Gourmet Food Canned, Jarred &amp; Packag...</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>Haldiram&amp;apos;s Bhelpuri - A Mild Spicy Blend ...</td>\n",
       "      <td>Haldiram&amp;apos;s Bhelpuri - A Mild Spicy Blend ...</td>\n",
       "      <td>Haldiram apos s Bhelpuri   A Mild Spicy Blend ...</td>\n",
       "      <td>Haldiram apos s Bhelpuri A Mild Spicy Blend Cr...</td>\n",
       "      <td>[Haldiram, apos, s, Bhelpuri, A, Mild, Spicy, ...</td>\n",
       "      <td>[haldiram, apos, s, bhelpuri, a, mild, spicy, ...</td>\n",
       "      <td>[haldiram, apo, s, bhelpuri, a, mild, spici, b...</td>\n",
       "      <td>haldiram apo s bhelpuri a mild spici blend cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kashmiri Mirch is a special blend of medium ho...</td>\n",
       "      <td>MDH</td>\n",
       "      <td>329,103 in Grocery &amp; Gourmet Food (</td>\n",
       "      <td></td>\n",
       "      <td>5478541265</td>\n",
       "      <td>MDH Kashmiri Mirch 100g</td>\n",
       "      <td>[]</td>\n",
       "      <td>Grocery &amp; Gourmet Food Canned, Jarred &amp; Packag...</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>Kashmiri Mirch is a special blend of medium ho...</td>\n",
       "      <td>Kashmiri Mirch special blend medium hot qualit...</td>\n",
       "      <td>Kashmiri Mirch special blend medium hot qualit...</td>\n",
       "      <td>Kashmiri Mirch special blend medium hot qualit...</td>\n",
       "      <td>[Kashmiri, Mirch, special, blend, medium, hot,...</td>\n",
       "      <td>[kashmiri, mirch, special, blend, medium, hot,...</td>\n",
       "      <td>[kashmiri, mirch, special, blend, medium, hot,...</td>\n",
       "      <td>kashmiri mirch special blend medium hot qualit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Gur Revdi is made by mixing Sesame seeds with ...</td>\n",
       "      <td>Swad</td>\n",
       "      <td>173,342 in Grocery &amp; Gourmet Food (</td>\n",
       "      <td>$9.28</td>\n",
       "      <td>618205610X</td>\n",
       "      <td>GUR REWDI - Jaggery Candy with Sesame Seeds 7o...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Grocery &amp; Gourmet Food Cooking &amp; Baking Nuts &amp;...</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>Gur Revdi is made by mixing Sesame seeds with ...</td>\n",
       "      <td>Gur Revdi made mixing Sesame seeds jaggery glu...</td>\n",
       "      <td>Gur Revdi made mixing Sesame seeds jaggery glu...</td>\n",
       "      <td>Gur Revdi made mixing Sesame seeds jaggery glu...</td>\n",
       "      <td>[Gur, Revdi, made, mixing, Sesame, seeds, jagg...</td>\n",
       "      <td>[gur, revdi, made, mixing, sesame, seeds, jagg...</td>\n",
       "      <td>[gur, revdi, made, mix, sesam, seed, jaggeri, ...</td>\n",
       "      <td>gur revdi made mix sesam seed jaggeri glucos t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          description      brand  \\\n",
       "1   Shipped from UK, please allow 10 to 21 busines...              \n",
       "13  Dishes cooked with nutrela are very tasty and ...    Nutrela   \n",
       "14  Haldiram&apos;s Bhelpuri - A Mild Spicy Blend ...  Haldirams   \n",
       "16  Kashmiri Mirch is a special blend of medium ho...        MDH   \n",
       "21  Gur Revdi is made by mixing Sesame seeds with ...       Swad   \n",
       "\n",
       "                                   rank   price        asin  \\\n",
       "1   315,867 in Grocery & Gourmet Food (          0853347867   \n",
       "13  195,125 in Grocery & Gourmet Food (  $24.99  5236363640   \n",
       "14   72,407 in Grocery & Gourmet Food (  $18.99  541255556X   \n",
       "16  329,103 in Grocery & Gourmet Food (          5478541265   \n",
       "21  173,342 in Grocery & Gourmet Food (   $9.28  618205610X   \n",
       "\n",
       "                                                 name features  \\\n",
       "1                           Trim Healthy Mama Xylitol       []   \n",
       "13  Nutrela High Protein Soya Chunks 200g (Pack of 6)       []   \n",
       "14  Haldiram's Bhelpuri - A Mild Spicy Blend of Cr...       []   \n",
       "16                            MDH Kashmiri Mirch 100g       []   \n",
       "21  GUR REWDI - Jaggery Candy with Sesame Seeds 7o...       []   \n",
       "\n",
       "                                           categories main_category  \\\n",
       "1   Grocery & Gourmet Food Cooking & Baking Sugar ...       Grocery   \n",
       "13  Grocery & Gourmet Food Canned, Jarred & Packag...       Grocery   \n",
       "14  Grocery & Gourmet Food Canned, Jarred & Packag...       Grocery   \n",
       "16  Grocery & Gourmet Food Canned, Jarred & Packag...       Grocery   \n",
       "21  Grocery & Gourmet Food Cooking & Baking Nuts &...       Grocery   \n",
       "\n",
       "                                             all_text  \\\n",
       "1   Shipped from UK, please allow 10 to 21 busines...   \n",
       "13  Dishes cooked with nutrela are very tasty and ...   \n",
       "14  Haldiram&apos;s Bhelpuri - A Mild Spicy Blend ...   \n",
       "16  Kashmiri Mirch is a special blend of medium ho...   \n",
       "21  Gur Revdi is made by mixing Sesame seeds with ...   \n",
       "\n",
       "                                           cleanText1  \\\n",
       "1   Shipped UK, please allow 10 21 business days a...   \n",
       "13  Dishes cooked nutrela tasty also natural nutri...   \n",
       "14  Haldiram&apos;s Bhelpuri - A Mild Spicy Blend ...   \n",
       "16  Kashmiri Mirch special blend medium hot qualit...   \n",
       "21  Gur Revdi made mixing Sesame seeds jaggery glu...   \n",
       "\n",
       "                                           cleanText2  \\\n",
       "1   Shipped UK  please allow 10 21 business days a...   \n",
       "13  Dishes cooked nutrela tasty also natural nutri...   \n",
       "14  Haldiram apos s Bhelpuri   A Mild Spicy Blend ...   \n",
       "16  Kashmiri Mirch special blend medium hot qualit...   \n",
       "21  Gur Revdi made mixing Sesame seeds jaggery glu...   \n",
       "\n",
       "                                           cleanText3  \\\n",
       "1   Shipped UK please allow business days arrival ...   \n",
       "13  Dishes cooked nutrela tasty also natural nutri...   \n",
       "14  Haldiram apos s Bhelpuri A Mild Spicy Blend Cr...   \n",
       "16  Kashmiri Mirch special blend medium hot qualit...   \n",
       "21  Gur Revdi made mixing Sesame seeds jaggery glu...   \n",
       "\n",
       "                                           cleanText4  \\\n",
       "1   [Shipped, UK, please, allow, business, days, a...   \n",
       "13  [Dishes, cooked, nutrela, tasty, also, natural...   \n",
       "14  [Haldiram, apos, s, Bhelpuri, A, Mild, Spicy, ...   \n",
       "16  [Kashmiri, Mirch, special, blend, medium, hot,...   \n",
       "21  [Gur, Revdi, made, mixing, Sesame, seeds, jagg...   \n",
       "\n",
       "                                           cleanText5  \\\n",
       "1   [shipped, uk, please, allow, business, days, a...   \n",
       "13  [dishes, cooked, nutrela, tasty, also, natural...   \n",
       "14  [haldiram, apos, s, bhelpuri, a, mild, spicy, ...   \n",
       "16  [kashmiri, mirch, special, blend, medium, hot,...   \n",
       "21  [gur, revdi, made, mixing, sesame, seeds, jagg...   \n",
       "\n",
       "                                           cleanText6  \\\n",
       "1   [ship, uk, pleas, allow, busi, day, arriv, ex,...   \n",
       "13  [dish, cook, nutrela, tasti, also, natur, nutr...   \n",
       "14  [haldiram, apo, s, bhelpuri, a, mild, spici, b...   \n",
       "16  [kashmiri, mirch, special, blend, medium, hot,...   \n",
       "21  [gur, revdi, made, mix, sesam, seed, jaggeri, ...   \n",
       "\n",
       "                                           cleanText7  \n",
       "1   ship uk pleas allow busi day arriv ex lib pub ...  \n",
       "13  dish cook nutrela tasti also natur nutrit good...  \n",
       "14  haldiram apo s bhelpuri a mild spici blend cri...  \n",
       "16  kashmiri mirch special blend medium hot qualit...  \n",
       "21  gur revdi made mix sesam seed jaggeri glucos t...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 96775 entries, 1 to 287050\n",
      "Data columns (total 17 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   description    96775 non-null  object\n",
      " 1   brand          96775 non-null  object\n",
      " 2   rank           96775 non-null  object\n",
      " 3   price          96775 non-null  object\n",
      " 4   asin           96775 non-null  object\n",
      " 5   name           96775 non-null  object\n",
      " 6   features       96775 non-null  object\n",
      " 7   categories     96775 non-null  object\n",
      " 8   main_category  96775 non-null  object\n",
      " 9   all_text       96775 non-null  object\n",
      " 10  cleanText1     96775 non-null  object\n",
      " 11  cleanText2     96775 non-null  object\n",
      " 12  cleanText3     96775 non-null  object\n",
      " 13  cleanText4     96775 non-null  object\n",
      " 14  cleanText5     96775 non-null  object\n",
      " 15  cleanText6     96775 non-null  object\n",
      " 16  cleanText7     96775 non-null  object\n",
      "dtypes: object(17)\n",
      "memory usage: 13.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_meta_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description      A harmony of chocolates and flowers which make...\n",
       "brand                                       Helen Grace Chocolates\n",
       "rank                           903,053 in Grocery & Gourmet Food (\n",
       "price                                                             \n",
       "asin                                                    B0000D89R5\n",
       "name             Helen Grace Chocolates, Long-Stemmed Truffle R...\n",
       "features                                                        []\n",
       "categories       Grocery & Gourmet Food Food & Beverage Gifts C...\n",
       "main_category                                              Grocery\n",
       "all_text         A harmony of chocolates and flowers which make...\n",
       "cleanText1       A harmony chocolates flowers makes truly memor...\n",
       "cleanText2       A harmony chocolates flowers makes truly memor...\n",
       "cleanText3       A harmony chocolates flowers makes truly memor...\n",
       "cleanText4       [A, harmony, chocolates, flowers, makes, truly...\n",
       "cleanText5       [a, harmony, chocolates, flowers, makes, truly...\n",
       "cleanText6       [a, harmoni, chocol, flower, make, truli, memo...\n",
       "cleanText7       a harmoni chocol flower make truli memor gift ...\n",
       "Name: 387, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_filtered.iloc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_meta_filtered = df_meta_filtered.drop(['cleanText1', 'cleanText2',\n",
    "#       'cleanText3', 'cleanText4', 'cleanText5', 'cleanText6'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_meta_filtered.to_csv('meta_filtred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5 = pd.read_csv('meta_filtred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96775 entries, 0 to 96774\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Unnamed: 0     96775 non-null  int64 \n",
      " 1   description    93021 non-null  object\n",
      " 2   brand          95510 non-null  object\n",
      " 3   rank           96775 non-null  object\n",
      " 4   price          44878 non-null  object\n",
      " 5   asin           96775 non-null  object\n",
      " 6   name           96775 non-null  object\n",
      " 7   features       96775 non-null  object\n",
      " 8   categories     96775 non-null  object\n",
      " 9   main_category  96775 non-null  object\n",
      " 10  all_text       96775 non-null  object\n",
      " 11  cleanText7     96775 non-null  object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 8.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_meta_life.to_csv('meta__all_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = d['asin'].isin(df_meta_['asin'])\n",
    "df2 = df2[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
